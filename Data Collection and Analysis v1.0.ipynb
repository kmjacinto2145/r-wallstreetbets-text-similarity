{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='6W9IFzMWNSjnUg', client_secret='wOIDztiKNDJFB1WdnOQR03_BDXgZlg', user_agent='mick43152')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape r/Conservative\n",
    "\n",
    "Conservative_posts = []\n",
    "Conservative_scraped = reddit.subreddit('Conservative').top(limit=10000)\n",
    "\n",
    "for post in Conservative_scraped:\n",
    "    Conservative_posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created_utc])\n",
    "Conservative_posts = pd.DataFrame(conservative_posts,columns=['title', 'score', 'id', 'url', 'comms_num', 'body', 'timestamp'])\n",
    "\n",
    "Conservative_posts[\"timestamp\"] = pd.to_datetime(Conservative_posts[\"timestamp\"], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file\n",
    "Conservative_posts.to_csv(\"Conservative_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape r/Libertarian\n",
    "\n",
    "Libertarian_posts = []\n",
    "Libertarian_scraped = reddit.subreddit('Libertarian').top(limit=10000)\n",
    "\n",
    "for post in Libertarian_scraped:\n",
    "    Libertarian_posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created_utc])\n",
    "Libertarian_posts = pd.DataFrame(Libertarian_posts,columns=['title', 'score', 'id', 'url', 'comms_num', 'body', 'timestamp'])\n",
    "\n",
    "Libertarian_posts[\"timestamp\"] = pd.to_datetime(Libertarian_posts[\"timestamp\"], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file\n",
    "Libertarian_posts.to_csv(\"Libertarian_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape r/Socialism\n",
    "\n",
    "Socialism_posts = []\n",
    "Socialism_scraped = reddit.subreddit('Socialism').top(limit=10000)\n",
    "\n",
    "for post in Socialism_scraped:\n",
    "    Socialism_posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created_utc])\n",
    "Socialism_posts = pd.DataFrame(Socialism_posts,columns=['title', 'score', 'id', 'url', 'comms_num', 'body', 'timestamp'])\n",
    "\n",
    "Socialism_posts[\"timestamp\"] = pd.to_datetime(Socialism_posts[\"timestamp\"], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file\n",
    "Socialism_posts.to_csv(\"Socialism_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_n_save(subreddit):\n",
    "    posts = []\n",
    "    scraped = reddit.subreddit(subreddit).top(limit=10000)\n",
    "    for post in scraped:\n",
    "        posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created_utc])\n",
    "    posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'url', 'comms_num', 'body', 'timestamp'])\n",
    "    \n",
    "    posts[\"timestamp\"] = pd.to_datetime(posts[\"timestamp\"], unit='s')\n",
    "    \n",
    "    filename = str(subreddit) + \"_posts.csv\"\n",
    "    \n",
    "    posts.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_to_scrape = [\"Conservative\", \"Libertarian\", \"Socialism\", \"Politics\", \"Economics\", \"Liberal\", \"Democrats\", \"Republican\", \"Marxism\", \"Communist\", \"Anarcho Capitalism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb_posts = pd.read_csv(\"reddit_wsb.csv\")\n",
    "Conservative_posts = pd.read_csv(\"Conservative_posts.csv\")\n",
    "Libertarian_posts = pd.read_csv(\"Libertarian_posts.csv\")\n",
    "Socialism_posts = pd.read_csv(\"Socialism_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb_headlines_doc = wsb_posts[\"title\"].str.cat(sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conservative_headlines_doc = Conservative_posts[\"title\"].str.cat(sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Libertarian_headlines_doc = Libertarian_posts[\"title\"].str.cat(sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Socialism_headlines_doc = Socialism_posts[\"title\"].str.cat(sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_similarity(doc1, doc2):\n",
    "    tfidf = TfidfVectorizer().fit_transform([doc1,doc2])\n",
    "    pairwise_similarity = tfidf * tfidf.T\n",
    "    print(pairwise_similarity.toarray()[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791414323695883\n"
     ]
    }
   ],
   "source": [
    "doc_similarity(wsb_headlines_doc, Conservative_headlines_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8189714501077735\n"
     ]
    }
   ],
   "source": [
    "doc_similarity(wsb_headlines_doc, Libertarian_headlines_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8022385461052035\n"
     ]
    }
   ],
   "source": [
    "doc_similarity(wsb_headlines_doc, Socialism_headlines_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2",
   "language": "python",
   "name": "data2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
